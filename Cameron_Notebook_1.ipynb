{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disaster Related Message Classification Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "Training Data for this text classification model comes from the **Figure Eight's** [Multilingual Disaster Response Messages](https://www.figure-eight.com/dataset/combined-disaster-response-data/). This dataset includes 30,000 messages drawn from a collection of natural disasters and news articles spanning a large number of years and 100s of different disasters. Most of the messages have been translated and contain labels for various disaster response categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in the csv to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "messages = pd.read_csv('datasets/disaster_response_messages_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 21046 rows and 42 columns.\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataframe has {} rows and {} columns.\".format(messages.shape[0], messages.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>split</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>PII</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>train</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>train</td>\n",
       "      <td>Information about the National Palace-</td>\n",
       "      <td>Informtion au nivaux palais nationl</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>train</td>\n",
       "      <td>Storm at sacred heart of jesus</td>\n",
       "      <td>Cyclone Coeur sacr de jesus</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  split                                            message  \\\n",
       "0   2  train  Weather update - a cold front from Cuba that c...   \n",
       "1   7  train            Is the Hurricane over or is it not over   \n",
       "2  12  train  says: west side of Haiti, rest of the country ...   \n",
       "3  14  train             Information about the National Palace-   \n",
       "4  15  train                     Storm at sacred heart of jesus   \n",
       "\n",
       "                                            original   genre  related  PII  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1    0   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1    0   \n",
       "2  facade ouest d Haiti et le reste du pays aujou...  direct        1    0   \n",
       "3                Informtion au nivaux palais nationl  direct        0    0   \n",
       "4                        Cyclone Coeur sacr de jesus  direct        1    0   \n",
       "\n",
       "   request  offer  aid_related      ...        aid_centers  \\\n",
       "0        0      0            0      ...                  0   \n",
       "1        0      0            1      ...                  0   \n",
       "2        0      0            0      ...                  0   \n",
       "3        0      0            0      ...                  0   \n",
       "4        0      0            0      ...                  0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                1       0      1     0           0   \n",
       "2                     0                0       0      0     0           0   \n",
       "3                     0                0       0      0     0           0   \n",
       "4                     0                1       0      1     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              0  \n",
       "2     0              0              0  \n",
       "3     0              0              0  \n",
       "4     0              0              0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "news      10450\n",
      "direct     8666\n",
      "social     1930\n",
      "Name: genre, dtype: int64\n",
      "\n",
      "related\n",
      "1    15795\n",
      "0     5083\n",
      "2      168\n",
      "Name: related, dtype: int64\n",
      "\n",
      "PII\n",
      "0    21046\n",
      "Name: PII, dtype: int64\n",
      "\n",
      "request\n",
      "0    17486\n",
      "1     3560\n",
      "Name: request, dtype: int64\n",
      "\n",
      "offer\n",
      "0    21046\n",
      "Name: offer, dtype: int64\n",
      "\n",
      "aid_related\n",
      "0    12361\n",
      "1     8685\n",
      "Name: aid_related, dtype: int64\n",
      "\n",
      "medical_help\n",
      "0    19392\n",
      "1     1654\n",
      "Name: medical_help, dtype: int64\n",
      "\n",
      "medical_products\n",
      "0    19975\n",
      "1     1071\n",
      "Name: medical_products, dtype: int64\n",
      "\n",
      "search_and_rescue\n",
      "0    20426\n",
      "1      620\n",
      "Name: search_and_rescue, dtype: int64\n",
      "\n",
      "security\n",
      "0    20644\n",
      "1      402\n",
      "Name: security, dtype: int64\n",
      "\n",
      "military\n",
      "0    20382\n",
      "1      664\n",
      "Name: military, dtype: int64\n",
      "\n",
      "child_alone\n",
      "0    21046\n",
      "Name: child_alone, dtype: int64\n",
      "\n",
      "water\n",
      "0    19725\n",
      "1     1321\n",
      "Name: water, dtype: int64\n",
      "\n",
      "food\n",
      "0    18717\n",
      "1     2329\n",
      "Name: food, dtype: int64\n",
      "\n",
      "shelter\n",
      "0    19168\n",
      "1     1878\n",
      "Name: shelter, dtype: int64\n",
      "\n",
      "clothing\n",
      "0    20723\n",
      "1      323\n",
      "Name: clothing, dtype: int64\n",
      "\n",
      "money\n",
      "0    20559\n",
      "1      487\n",
      "Name: money, dtype: int64\n",
      "\n",
      "missing_people\n",
      "0    20794\n",
      "1      252\n",
      "Name: missing_people, dtype: int64\n",
      "\n",
      "refugees\n",
      "0    20328\n",
      "1      718\n",
      "Name: refugees, dtype: int64\n",
      "\n",
      "death\n",
      "0    20082\n",
      "1      964\n",
      "Name: death, dtype: int64\n",
      "\n",
      "other_aid\n",
      "0    18170\n",
      "1     2876\n",
      "Name: other_aid, dtype: int64\n",
      "\n",
      "infrastructure_related\n",
      "0    19608\n",
      "1     1438\n",
      "Name: infrastructure_related, dtype: int64\n",
      "\n",
      "transport\n",
      "0    20098\n",
      "1      948\n",
      "Name: transport, dtype: int64\n",
      "\n",
      "buildings\n",
      "0    19952\n",
      "1     1094\n",
      "Name: buildings, dtype: int64\n",
      "\n",
      "electricity\n",
      "0    20597\n",
      "1      449\n",
      "Name: electricity, dtype: int64\n",
      "\n",
      "tools\n",
      "0    20906\n",
      "1      140\n",
      "Name: tools, dtype: int64\n",
      "\n",
      "hospitals\n",
      "0    20818\n",
      "1      228\n",
      "Name: hospitals, dtype: int64\n",
      "\n",
      "shops\n",
      "0    20947\n",
      "1       99\n",
      "Name: shops, dtype: int64\n",
      "\n",
      "aid_centers\n",
      "0    20788\n",
      "1      258\n",
      "Name: aid_centers, dtype: int64\n",
      "\n",
      "other_infrastructure\n",
      "0    20058\n",
      "1      988\n",
      "Name: other_infrastructure, dtype: int64\n",
      "\n",
      "weather_related\n",
      "0    15181\n",
      "1     5865\n",
      "Name: weather_related, dtype: int64\n",
      "\n",
      "floods\n",
      "0    19349\n",
      "1     1697\n",
      "Name: floods, dtype: int64\n",
      "\n",
      "storm\n",
      "0    19073\n",
      "1     1973\n",
      "Name: storm, dtype: int64\n",
      "\n",
      "fire\n",
      "0    20807\n",
      "1      239\n",
      "Name: fire, dtype: int64\n",
      "\n",
      "earthquake\n",
      "0    19067\n",
      "1     1979\n",
      "Name: earthquake, dtype: int64\n",
      "\n",
      "cold\n",
      "0    20621\n",
      "1      425\n",
      "Name: cold, dtype: int64\n",
      "\n",
      "other_weather\n",
      "0    19908\n",
      "1     1138\n",
      "Name: other_weather, dtype: int64\n",
      "\n",
      "direct_report\n",
      "0    17037\n",
      "1     4009\n",
      "Name: direct_report, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting a sense of the types of values in the dataset. Mostly 1 hot encoded labels for the messages\n",
    "for i in messages.columns[4:]:\n",
    "    print(i)\n",
    "    print(messages[i].value_counts())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Information about the National Palace-</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Storm at sacred heart of jesus</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message   genre  related  \\\n",
       "0  Weather update - a cold front from Cuba that c...  direct        1   \n",
       "1            Is the Hurricane over or is it not over  direct        1   \n",
       "2  says: west side of Haiti, rest of the country ...  direct        1   \n",
       "3             Information about the National Palace-  direct        0   \n",
       "4                     Storm at sacred heart of jesus  direct        1   \n",
       "\n",
       "   request  aid_related  medical_help  medical_products  search_and_rescue  \\\n",
       "0        0            0             0                 0                  0   \n",
       "1        0            1             0                 0                  0   \n",
       "2        0            0             0                 0                  0   \n",
       "3        0            0             0                 0                  0   \n",
       "4        0            0             0                 0                  0   \n",
       "\n",
       "   security  military      ...        aid_centers  other_infrastructure  \\\n",
       "0         0         0      ...                  0                     0   \n",
       "1         0         0      ...                  0                     0   \n",
       "2         0         0      ...                  0                     0   \n",
       "3         0         0      ...                  0                     0   \n",
       "4         0         0      ...                  0                     0   \n",
       "\n",
       "   weather_related  floods  storm  fire  earthquake  cold  other_weather  \\\n",
       "0                0       0      0     0           0     0              0   \n",
       "1                1       0      1     0           0     0              0   \n",
       "2                0       0      0     0           0     0              0   \n",
       "3                0       0      0     0           0     0              0   \n",
       "4                1       0      1     0           0     0              0   \n",
       "\n",
       "   direct_report  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We dropped columns that do not have a diverse spread of values - based on the above exploration.\n",
    "# e.g. all values in column 'PII' are 0 - this gives us no valuable information for classification.\n",
    "messages.drop(columns = ['id', 'split', 'original', 'PII', 'offer', 'child_alone'], inplace=True)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 0 null values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Dropping duplicate messages\n",
    "messages = messages.drop_duplicates(subset='message')\n",
    "\n",
    "# Check for nulls\n",
    "print('There are now {} null values in the dataset.'.format(messages.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the TARGET variable for Model 1\n",
    "\n",
    "- 1 : Urgent Action Needed\n",
    "\n",
    "- 2 : Non-urgent action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['urgent_label'] = messages['genre'].map(lambda x: 1 if x == 'direct'  else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Creating the TARGET variable for Model 2__\n",
    "The impetus for a second model was to reduce misclassification of our target variable \"Direct Media\". By predicting more than just binary categories, we could potentially reduce the number of false negatives (predictions that an urgent message for help is non-urgent) and prevent ignoring messages from those that need help.\n",
    "\n",
    "- 0 : News media\n",
    "- 1 : Direct media - Urgent Action Needed!\n",
    "- 2 : Social media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['genre_label'] = messages['genre'].replace(['direct', 'news', 'social'], [1, 0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for modeling\n",
    " Tokenizing, Lemmatizing, and Stemming the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a text preprocessing function that get our data ready for modeling, creating new columns \n",
    "# for the message text in their tokenized, lemmatized, and stemmed forms. This allows for easy selection\n",
    "# of different forms of the text for use in vectorization and modeling.\n",
    "\n",
    "def preprocessed_columns(dataframe = messages, \n",
    "                        column = 'message', \n",
    "                        new_lemma_column = 'lemmatized', \n",
    "                        new_stem_column = 'stemmed',\n",
    "                        new_token_column = 'tokenized_message',\n",
    "                        regular_expression = r'\\w+'): \n",
    "    \n",
    "    tokenizer = RegexpTokenizer(regular_expression)      #Instantiate tokenizer with specific regular expression\n",
    "    lemmatizer = WordNetLemmatizer()                     #Instantiate lemmatizer\n",
    "    stemmer = PorterStemmer()                            #Instantiate stemmer\n",
    "    \n",
    "    lemmatized = []                                      #list to append lemmatized data\n",
    "    stemmed = []                                         #list to append stemmed words\n",
    "    tokenized = []\n",
    "    \n",
    "    \n",
    "    for i in dataframe[column]:                          #Iterate through all the rows in specific column\n",
    "\n",
    "        tokens = tokenizer.tokenize(i.lower())           #Converting string titles to tokens \n",
    "        tokenized.append(tokens)\n",
    "\n",
    "        lemma = [lemmatizer.lemmatize(token) for token in tokens]     #lemmatizing all tokens\n",
    "        lemmatized.append(lemma)                                      #appending lemma to lemmatized list\n",
    "\n",
    "        stems = [stemmer.stem(token) for token in tokens]             #stemming all tokens\n",
    "        stemmed.append(stems)                                         #creating stem list\n",
    "     \n",
    "    dataframe[new_token_column] = [' '.join(i) for i in tokenized]    \n",
    "    dataframe[new_lemma_column] = [' '.join(i) for i in lemmatized]   #rejoing the lists for each title\n",
    "    dataframe[new_stem_column] = [' '.join(i) for i in stemmed]       #setting results to be new columns in df   \n",
    "    \n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>message</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>...</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "      <th>urgent_label</th>\n",
       "      <th>genre_label</th>\n",
       "      <th>tokenized_message</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>weather update a cold front from cuba that cou...</td>\n",
       "      <td>weather update a cold front from cuba that cou...</td>\n",
       "      <td>weather updat a cold front from cuba that coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>is the hurricane over or is it not over</td>\n",
       "      <td>is the hurricane over or is it not over</td>\n",
       "      <td>is the hurrican over or is it not over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>says west side of haiti rest of the country to...</td>\n",
       "      <td>say west side of haiti rest of the country tod...</td>\n",
       "      <td>say west side of haiti rest of the countri tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Information about the National Palace-</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>information about the national palace</td>\n",
       "      <td>information about the national palace</td>\n",
       "      <td>inform about the nation palac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Storm at sacred heart of jesus</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>storm at sacred heart of jesus</td>\n",
       "      <td>storm at sacred heart of jesus</td>\n",
       "      <td>storm at sacr heart of jesu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            message   genre  related  \\\n",
       "0      0  Weather update - a cold front from Cuba that c...  direct        1   \n",
       "1      1            Is the Hurricane over or is it not over  direct        1   \n",
       "2      2  says: west side of Haiti, rest of the country ...  direct        1   \n",
       "3      3             Information about the National Palace-  direct        0   \n",
       "4      4                     Storm at sacred heart of jesus  direct        1   \n",
       "\n",
       "   request  aid_related  medical_help  medical_products  search_and_rescue  \\\n",
       "0        0            0             0                 0                  0   \n",
       "1        0            1             0                 0                  0   \n",
       "2        0            0             0                 0                  0   \n",
       "3        0            0             0                 0                  0   \n",
       "4        0            0             0                 0                  0   \n",
       "\n",
       "   security                        ...                          fire  \\\n",
       "0         0                        ...                             0   \n",
       "1         0                        ...                             0   \n",
       "2         0                        ...                             0   \n",
       "3         0                        ...                             0   \n",
       "4         0                        ...                             0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  urgent_label  genre_label  \\\n",
       "0           0     0              0              0             1            1   \n",
       "1           0     0              0              0             1            1   \n",
       "2           0     0              0              0             1            1   \n",
       "3           0     0              0              0             1            1   \n",
       "4           0     0              0              0             1            1   \n",
       "\n",
       "                                   tokenized_message  \\\n",
       "0  weather update a cold front from cuba that cou...   \n",
       "1            is the hurricane over or is it not over   \n",
       "2  says west side of haiti rest of the country to...   \n",
       "3              information about the national palace   \n",
       "4                     storm at sacred heart of jesus   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  weather update a cold front from cuba that cou...   \n",
       "1            is the hurricane over or is it not over   \n",
       "2  say west side of haiti rest of the country tod...   \n",
       "3              information about the national palace   \n",
       "4                     storm at sacred heart of jesus   \n",
       "\n",
       "                                             stemmed  \n",
       "0  weather updat a cold front from cuba that coul...  \n",
       "1             is the hurrican over or is it not over  \n",
       "2  say west side of haiti rest of the countri tod...  \n",
       "3                      inform about the nation palac  \n",
       "4                        storm at sacr heart of jesu  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling the above function and resetting the messages dataframe\n",
    "messages = preprocessed_columns()\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearching Hyperparameters for Word Vectorization and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_model(X_column, model, vectorizer, params, verbose = 1):\n",
    "    \n",
    "    X = messages[X_column]                                    #creates X and y\n",
    "    y = messages['urgent_label']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)    #train test split\n",
    "    \n",
    "    pipe = Pipeline([                               #pipeline to run with gridsearch and test hyperparameters\n",
    "        ('vectorizer', vectorizer),                 #for both the model and vectorizer.\n",
    "        ('model', model)])                          #this will be done for many vectorizer-model combinations\n",
    "        \n",
    "    grid = GridSearchCV(pipe, param_grid=params, cv=5, verbose=verbose)  \n",
    "    \n",
    "    grid.fit(X_train, y_train)                       #fitting the grid model to X_train and y_train and \n",
    "                                                     #running a 5 fold cross validation\n",
    "    score_dict = {}\n",
    "    \n",
    "    score_dict['X'] = X_column                               #this dict will be converted to dataframe to store \n",
    "    score_dict['Vectorizer'] = vectorizer                    #the performance of each gridsearch and return the \n",
    "    score_dict['Model'] = model                              #best parameters and score to compare to other models\n",
    "    score_dict['train_score'] = grid.score(X_train, y_train)\n",
    "    score_dict['test_score'] = grid.score(X_test, y_test)\n",
    "    score_dict['best_params'] = grid.best_params_\n",
    "    \n",
    "    try:\n",
    "        return pd.DataFrame(score_dict)\n",
    "    except:\n",
    "        return score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing Tokenize Messages and Modeling with Logistic Regression\n",
    "We chose Logistic Regression for it's high interpretability. This will tell us what words or n-grams are informative for predicting urgent help messages. This linguistic inference can be applied to future modeling efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text Selected - Tokenized messsages\n",
    "# Running a gridsearch on Logistic Regression and Count Vectorizer \n",
    "\n",
    "logreg = LogisticRegression()\n",
    "cv = CountVectorizer()\n",
    "\n",
    "params = {'vectorizer__stop_words': ['english', None],\n",
    "          'vectorizer__max_features':[None],\n",
    "          'vectorizer__ngram_range':[(1,1), (1,2), (1,3)],\n",
    "          'vectorizer__min_df':[1],\n",
    "          'vectorizer__max_df':[1.0],\n",
    "          'model__penalty':['l2']\n",
    "         }\n",
    "\n",
    "count_vect_logreg = text_to_model(X_column='tokenized_message', model = logreg, vectorizer=cv, params=params)\n",
    "count_vect_logreg\n",
    "\n",
    "# Best Params Below: \n",
    "# Logistic Regression with Ridge Penatly\n",
    "# Count Vectorizer with No max features, min_df = 1, ngrams = (1,2), Stop_words = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Term Frequency - Inverse Document Frequency Word Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text Selected - Tokenized Message\n",
    "# Gridsearching Hyperparameters for TF-IDF Vectorizer\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "params = {'vectorizer__stop_words': ['english', None],\n",
    "          'vectorizer__max_features':[None, 10000, 20000],\n",
    "          'vectorizer__ngram_range':[(1,1), (1,2), (1,3)],\n",
    "          'vectorizer__min_df':[1],\n",
    "          'vectorizer__max_df':[1.0],\n",
    "          'model__penalty':['l2']\n",
    "         }\n",
    "\n",
    "count_vect_logreg = text_to_model(X_column='tokenized_message', model = logreg, vectorizer=cv, params=params)\n",
    "count_vect_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gridsearching on __Lemmatized Messages__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "cv = CountVectorizer()\n",
    "\n",
    "params = {'vectorizer__stop_words': ['english', None],\n",
    "          'vectorizer__max_features':[None, 50000, 100000, 200000],\n",
    "          'vectorizer__ngram_range':[(1,2), (1,3)],\n",
    "          'vectorizer__min_df':[1],\n",
    "          'vectorizer__max_df':[1.0],\n",
    "          'model__penalty':['l2']\n",
    "         }\n",
    "\n",
    "count_vect_logreg = text_to_model(X_column='lemmatized', model = logreg, vectorizer=cv, params=params)\n",
    "count_vect_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gridsearching Word Vectorizer Hyperparameters with Tokenized Messages**\n",
    "\n",
    "While the score is slightly higher for tokenized text, we decided to stick with lemmatized because it can maintain some broader meaning than just focusing on the stem of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "cv = CountVectorizer()\n",
    "\n",
    "params = {'vectorizer__stop_words': ['english', None],\n",
    "          'vectorizer__max_features':[None, 50000, 100000, 200000],\n",
    "          'vectorizer__ngram_range':[(1,2), (1,3)],\n",
    "          'vectorizer__min_df':[1],\n",
    "          'vectorizer__max_df':[1.0],\n",
    "          'model__penalty':['l2']\n",
    "         }\n",
    "\n",
    "count_vect_logreg = text_to_model(X_column='stemmed', model = logreg, vectorizer=cv, params=params)\n",
    "count_vect_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Final Modeling\n",
    "### Word Vectorization with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urgent_label</th>\n",
       "      <th>genre</th>\n",
       "      <th>genre_label</th>\n",
       "      <th>00</th>\n",
       "      <th>00 am</th>\n",
       "      <th>00 in</th>\n",
       "      <th>000</th>\n",
       "      <th>000 000</th>\n",
       "      <th>000 acre</th>\n",
       "      <th>000 affected</th>\n",
       "      <th>...</th>\n",
       "      <th>zwaar</th>\n",
       "      <th>àö</th>\n",
       "      <th>àö and</th>\n",
       "      <th>àö http</th>\n",
       "      <th>àö in</th>\n",
       "      <th>àö to</th>\n",
       "      <th>àö tom</th>\n",
       "      <th>àö àö</th>\n",
       "      <th>àû</th>\n",
       "      <th>àû elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   urgent_label   genre  genre_label  00  00 am  00 in  000  000 000  \\\n",
       "0             1  direct            1   0      0      0    0        0   \n",
       "1             1  direct            1   0      0      0    0        0   \n",
       "2             1  direct            1   0      0      0    0        0   \n",
       "3             1  direct            1   0      0      0    0        0   \n",
       "4             1  direct            1   0      0      0    0        0   \n",
       "\n",
       "   000 acre  000 affected      ...       zwaar  àö  àö and  àö http  àö in  \\\n",
       "0         0             0      ...           0   0       0        0      0   \n",
       "1         0             0      ...           0   0       0        0      0   \n",
       "2         0             0      ...           0   0       0        0      0   \n",
       "3         0             0      ...           0   0       0        0      0   \n",
       "4         0             0      ...           0   0       0        0      0   \n",
       "\n",
       "   àö to  àö tom  àö àö  àû  àû elevation  \n",
       "0      0       0      0   0             0  \n",
       "1      0       0      0   0             0  \n",
       "2      0       0      0   0             0  \n",
       "3      0       0      0   0             0  \n",
       "4      0       0      0   0             0  \n",
       "\n",
       "[5 rows x 50003 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec = CountVectorizer(ngram_range = (1,2), max_features = 50000)\n",
    "X = count_vec.fit_transform(messages['lemmatized'])\n",
    "cv_messages = pd.DataFrame(X.toarray(), columns = count_vec.get_feature_names())\n",
    "cv_messages.insert(loc = 0, column = 'urgent_label', value = messages['urgent_label'])\n",
    "cv_messages.insert(loc = 1, column = 'genre', value = messages['genre'])\n",
    "cv_messages.insert(loc = 2, column = 'genre_label', value = messages['genre_label'])\n",
    "cv_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20992, 50003)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_messages.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split for Model 1 (binary categories)\n",
    "X_train, X_test, y_train, y_test = train_test_split(cv_messages.drop(columns = ['urgent_label', 'genre', 'genre_label']),\n",
    "                                                    cv_messages['urgent_label'],\n",
    "                                                    random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Model:\n",
    "##### We chose Logistic Regression for it's high performance and interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987931910569106"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Score\n",
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9641768292682927"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Score\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making prediction on the Test Data\n",
    "logreg_predictions = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Non-Urgent</th>\n",
       "      <th>Predicted Urgent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Non-Urgent</th>\n",
       "      <td>2972</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Urgent</th>\n",
       "      <td>99</td>\n",
       "      <td>2088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted Non-Urgent  Predicted Urgent\n",
       "Actual Non-Urgent                  2972                89\n",
       "Actual Urgent                        99              2088"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a table for correct and incorrect predictions\n",
    "cm = confusion_matrix(y_test, logreg_predictions)\n",
    "confusion_test_df = pd.DataFrame(data = cm, columns = ['Predicted Non-Urgent', 'Predicted Urgent'],\n",
    "                                 index = ['Actual Non-Urgent', 'Actual Urgent'])\n",
    "confusion_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score is: 0.9735137195121951\n",
      "The Misclassification Rate is: 0.02648628048780488\n",
      "The Sensitivity is: 0.9679926840420667\n",
      "The Specificity is: 0.9774583469454426\n"
     ]
    }
   ],
   "source": [
    "# accuracy = TP + TN / Total\n",
    "accuracy = (2992 + 2117) / (2992 + 2117 + 70 + 69)\n",
    "print(\"The Accuracy Score is: {}\".format(accuracy))\n",
    "\n",
    "# misclassification rate = 1 - accuracy\n",
    "misclassification = 1 - accuracy\n",
    "print(\"The Misclassification Rate is: {}\".format(misclassification))\n",
    "\n",
    "# sensitivity = TP / TP + FN\n",
    "sensitivity = 2117 / (2117 + 70)\n",
    "print(\"The Sensitivity is: {}\".format(sensitivity))\n",
    "\n",
    "# specificity = TN / TN + FP\n",
    "specificity = 2992 / (2992 + 69)\n",
    "print(\"The Specificity is: {}\".format(specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Y-Test dataframe compares original category labels with model predictions. This allows us to investigate misclassified methods to qualitatively understanding where our model fails to predict urgency in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urgent_label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       urgent_label  prediction\n",
       "14550             0           0\n",
       "14983             0           0\n",
       "6100              1           1\n",
       "5300              1           1\n",
       "5998              1           1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df = pd.DataFrame(data = y_test)\n",
    "y_test_df['prediction'] = logreg_predictions\n",
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n"
     ]
    }
   ],
   "source": [
    "# \"misclassified\" is the subset of y_test_df that only contains the misclassified messages\n",
    "misclassified = y_test_df[y_test_df['urgent_label'] != y_test_df['prediction']]\n",
    "print(len(misclassified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text from the messages that were originally labeled as \"urgent\" but classified as \"non-urgent\"\n",
    "# These are our \"False Negatives\"\n",
    "\n",
    "count = 0\n",
    "for i in messages.iloc[misclassified[misclassified['prediction'] == 0].index]['message']:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    print(i)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text from the messages that were originally labeled as \"non-urgent\" but classified as \"urgent\"\n",
    "count = 0\n",
    "for i in messages.iloc[misclassified[misclassified['prediction'] == 1].index]['message']:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    print(i)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to create a dataframe with the 50-100 most and \n",
    "# least correlated words (columns) from messages_cv\n",
    "\n",
    "best_features = pd.DataFrame(data = X_test.columns, columns = ['Top Features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features['Coefficient'] = logreg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#best_features['Coefficient'].sort_values(ascending=False).head(100)\n",
    "top_feature_words = best_features[best_features['Coefficient'] > 0.749108].sort_values(by = 'Coefficient', ascending=False)\n",
    "top_feature_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#best_features['Coefficient'].sort_values().head(100)\n",
    "negative_class_feature_words = best_features[best_features['Coefficient'] \n",
    "                                             < -0.763026].sort_values(by='Coefficient')\n",
    "negative_class_feature_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Most Informative Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to create a dataframe with the 50-100 most and \n",
    "# least correlated words (columns) from messages_cv\n",
    "\n",
    "best_features_3_classes = pd.DataFrame(data = X_test_3.columns, columns = ['Top Features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_3_classes['Coefficient'] = logreg_3.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#best_features_3_classes['Coefficient'].sort_values(ascending=False).head(100)\n",
    "top_feature_words_3_classes = best_features_3_classes[best_features_3_classes['Coefficient'] > 0.749108].sort_values(by = 'Coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_feature_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_features['Coefficient'].sort_values().head(100)\n",
    "#negative_class_feature_words = best_features[best_features['Coefficient'] < -0.763026].sort_values(by='Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Model 1 on Data from another source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate = pd.read_csv('./datasets/natural_disaster_tweets.csv')\n",
    "validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The dataframe has {} rows and {} columns.\".format(validate.shape[0], validate.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The dataframe has {} rows and {} columns.\".format(validate.shape[0], validate.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorizing the Validation DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_cv = count_vec.transform(validate['lemmatized_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions = list(logreg.predict(validate_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate['predictions'] = validation_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A subset of messages from validation dataset that were predicted \"urgent\"\n",
    "\n",
    "count = 0\n",
    "for i in validate[validate['predictions'] == 1]['Tweet'][:100]:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    print('')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A subset of messages from validation dataset that were predicted \" NOT urgent\"\n",
    "\n",
    "count = 0\n",
    "for i in validate[validate['predictions'] == 0]['Tweet'][:100]:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    print('')\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
